# -*- coding: utf-8 -*-
"""Salinan Salinan Water Temp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mgSRdMDWC4qwT6b4UPfPDtPXNREQTi7h
"""

#importing libraries
import locale
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
import matplotlib.dates as mdates
import statsmodels.api as sm
import itertools
from pandas import DataFrame
from matplotlib import pyplot
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf,plot_pacf
from tqdm.auto import tqdm
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from datetime import datetime, timedelta
from scipy.stats import linregress
from scipy.fft import fft
from pandas.plotting import autocorrelation_plot
from scipy.stats import shapiro
from scipy.stats import kstest, norm
from sklearn.metrics import mean_squared_error
from pmdarima import auto_arima
from math import sqrt
from statsmodels.tools.eval_measures import  rmse
from statsmodels.tsa.arima.model import ARIMA

pip install pmdarima

import warnings

warnings.filterwarnings("ignore")
pd.set_option('display.float_format', '{:.2f}'.format)
plt.rcParams['figure.figsize'] = (10, 6)

# importing dataset
temp = pd.read_csv('skypiancolection-data.csv')
temp.head()

temp.info()

#datatypes of data
temp.dtypes

temp.shape

temp.rename(columns={'04/08/2023 00:32:40': 'timestamp', '25.0': 'watertemp', '24.0': 'airtemp', '98':'humidity', '25':'hix'}, inplace=True)

print(temp)

# Konversi kolom 'timestamp' menjadi tipe data datetime dengan format yang diinginkan
temp['timestamp'] = pd.to_datetime(temp['timestamp'], format='%d/%m/%Y %H:%M:%S')

# Menampilkan DataFrame yang sudah diubah
print(temp)

temp.info()

temp.isnull().sum()

temp = temp[4330:]

# Hapus data duplikat berdasarkan kolom timestamp
temp.drop_duplicates(subset='timestamp', inplace=True)

temp.shape

temp['timestamp'] = pd.to_datetime(temp['timestamp'])
temp.set_index('timestamp', inplace=True)

print(temp)

# Set lokalisasi ke format tanggal "dd-mm-yy"
locale.setlocale(locale.LC_TIME, 'en_US.utf8')  # Ganti 'id_ID.utf8' dengan lokalisasi yang sesuai

# Lakukan resampling
temp = temp.resample('H').mean()

print(temp)

# Menghapus kolom 'airtemp'
temp.drop('airtemp', axis=1, inplace=True)

# Cetak DataFrame setelah menghapus kolom 'airtemp'
print(temp)

# Mengecek dan menghapus baris yang mengandung nilai NaN
temp = temp.dropna()

print("DataFrame setelah menghapus NaN:")
print(temp)

print(temp)

# Mengambil data yang ingin diuji stasioneritasnya
data_to_test = temp['watertemp']  # Ganti 'column_name' dengan nama kolom data yang ingin diuji

# Melakukan uji ADF
result = adfuller(data_to_test)

# Mencetak hasil uji ADF
print('ADF Statistic:', result[0])
print('p-value:', result[1])
print('Critical Values:')
for key, value in result[4].items():
    print(f'   {key}: {value}')

plt.figure(figsize=(12, 6))
plt.plot(temp.index, temp['watertemp'], label='Data')
plt.title('Time Series Plot')
plt.xlabel('Tanggal')
plt.ylabel('Suhu Air')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(8, 4))
plt.hist(temp['watertemp'], bins=20, color='blue', alpha=0.7)
plt.title('Histogram')
plt.xlabel('Suhu Air')
plt.ylabel('Frekuensi')
plt.grid(True)
plt.show()

seasonal_period = 6  # Gantilah dengan periode musiman yang sesuai
decomposition = seasonal_decompose(temp['watertemp'], model='additive', period=seasonal_period)
decomposition.plot()
plt.show()

# Melakukan regresi linier
slope, intercept, r_value, p_value, std_err = linregress(range(len(temp)), temp['watertemp'])

if p_value < 0.05:
    print("Terdapat tren signifikan dalam data.")
else:
    print("Tidak ada tren yang signifikan dalam data.")

# Ambil data suhu air sebagai array NumPy
watertemp = temp['watertemp'].values

# Melakukan analisis frekuensi
fft_result = np.fft.fft(watertemp)
amplitudes = 2.0 / len(temp) * np.abs(fft_result[:len(temp) // 2])

# Mengidentifikasi frekuensi dominan
dominant_frequency = np.argmax(amplitudes)

if dominant_frequency > 0:
    print(f"Terdapat komponen musiman dengan frekuensi {dominant_frequency} dalam data.")
else:
    print("Tidak ada komponen musiman yang signifikan dalam data.")

# Scatter plot untuk melihat pola
plt.scatter(temp.index, temp['watertemp'], s=5)
plt.title('Scatter Plot')
plt.xlabel('Tanggal')
plt.ylabel('Suhu Air')
plt.grid(True)
plt.show()

# Plot autocorrelation
autocorrelation_plot(temp['watertemp'])
plt.title('Autocorrelation Plot')
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.show()

# Uji normalitas
_, p_value = shapiro(temp['watertemp'])

if p_value < 0.05:
    print("Data tidak terdistribusi normal.")
else:
    print("Data terdistribusi normal.")

# Menggunakan uji Kolmogorov-Smirnov dengan distribusi normal sebagai referensi
kstest_result = kstest(temp['watertemp'], 'norm')  # Ganti 'column_name' dengan nama kolom data yang ingin diuji

# Menentukan apakah data terdistribusi normal
alpha = 0.05  # Tingkat signifikansi
if kstest_result.pvalue > alpha:
    print("Data terdistribusi normal.")
else:
    print("Data tidak terdistribusi normal.")

# Mengidentifikasi tanggal terakhir dengan jumlah data yang cukup (misalnya, dua hari terakhir)
cutoff_date = temp.index.max() - pd.DateOffset(days=1)

# Memisahkan data menjadi data latih dan data uji berdasarkan cutoff_date
train_data = temp[temp.index <= cutoff_date]
test_data = temp[temp.index > cutoff_date]

print(train_data)

print(test_data)

stepwise_fit = auto_arima(temp['watertemp'], trace=True,
                          suppress_warnings=True)
stepwise_fit.summary()

# Membuat dan melatih model ARIMA(2, 0, 3)
model = ARIMA(train_data['watertemp'], order=(2, 0, 3))
model_fit = model.fit()

# Melihat ringkasan model
print(model_fit.summary())

# line plot of residuals
residuals = DataFrame(model_fit.resid)
residuals.plot()
pyplot.show()
# density plot of residuals
residuals.plot(kind='kde')
pyplot.show()
# summary stats of residuals
print(residuals.describe())

# split into train and test sets
X = temp.values
size = int(len(X) * 0.66)
train= train_data["watertemp"].values
test= test_data["watertemp"].values
history = [x for x in train_data['watertemp']]
predictions = list()

print(test)

print(history)

# walk-forward validation
for t in range(len(test)):
 model = ARIMA(history, order=(2, 0, 3))
 model_fit = model.fit()
 output = model_fit.forecast()
 yhat = output[0]
 predictions.append(yhat)
 obs = test[t]
 history.append(obs)
 print('predicted=%f, expected=%f' % (yhat, obs))

# evaluate forecasts
rmse = sqrt(mean_squared_error(test, predictions))

print('Test RMSE: %.3f' % rmse)

pyplot.plot(test)
pyplot.plot(predictions, color='red')
pyplot.show()

# Misalnya, Anda memiliki nilai MSE dari model ARIMA dan variansi data
mse_model = 3.306**2  # Gantilah dengan nilai MSE model Anda
variance_data = np.var(test)  # Gantilah dengan variansi data aktual

# Menghitung tingkat akurasi dalam persentase
accuracy = 100 * (1 - (mse_model / variance_data))

# Menampilkan tingkat akurasi
print("Tingkat Akurasi Model ARIMA:", accuracy, "%")

model2=ARIMA(train_data['watertemp'],order=(2, 0, 3))
model2=model2.fit()

index_future_dates=pd.date_range(start='2023-08-30 17:00:00', periods=7, freq='H')
pred=model2.predict(start=len(train_data),end=len(train_data)+6,type='levels').rename('ARIMA Predictions')
pred.index=index_future_dates

print(pred)

pyplot.plot(temp)
pyplot.plot(pred, color='red')
pyplot.show()

from google.colab import drive
drive.mount('/content/drive')

